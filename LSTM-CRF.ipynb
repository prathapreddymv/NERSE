{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"crftag1000.tsv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.fillna(method=\"ffill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92764</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>good</td>\n",
       "      <td>JJ</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92765</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>practice</td>\n",
       "      <td>NN</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92766</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92767</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>welcome</td>\n",
       "      <td>JJ</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92768</th>\n",
       "      <td>Sentence: 1000</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sentence #      Word  POS Tag\n",
       "92764  Sentence: 1000      good   JJ   o\n",
       "92765  Sentence: 1000  practice   NN   o\n",
       "92766  Sentence: 1000        is  VBZ   o\n",
       "92767  Sentence: 1000   welcome   JJ   o\n",
       "92768  Sentence: 1000         .    .   o"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10044"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('On', 'IN', 'o'), ('one', 'CD', 'o'), ('Linux', 'NNP', 'OS&SystemKernels'), ('Server', 'NNP', 'o'), ('running', 'VBG', 'o'), ('Apache', 'NNP', 'o'), ('and', 'CC', 'o'), ('PHP', 'NNP', 'Web development'), ('5', 'CD', 'o'), (',', ',', 'o'), ('we', 'PRP', 'o'), ('got', 'VBD', 'o'), ('multiple', 'JJ', 'o'), ('Virtual', 'NNP', 'o'), ('Hosts', 'VBZ', 'o'), ('with', 'IN', 'o'), ('separate', 'JJ', 'o'), ('log', 'NN', 'o'), ('files', 'NNS', 'o'), ('and', 'CC', 'o'), ('everything', 'NN', 'o'), ('.', '.', 'o'), ('The', 'DT', 'o'), ('only', 'JJ', 'o'), ('thing', 'NN', 'o'), ('we', 'PRP', 'o'), ('can', 'MD', 'o'), ('not', 'RB', 'o'), ('seem', 'VB', 'o'), ('to', 'TO', 'o'), ('separate', 'VB', 'o'), ('between', 'IN', 'o'), ('virtual', 'JJ', 'o'), ('hosts', 'NNS', 'o'), ('is', 'VBZ', 'o'), ('the', 'DT', 'o'), ('php', 'NN', 'Web development'), ('.', '.', 'o'), ('Overriding', 'VBG', 'o'), ('this', 'DT', 'o'), ('setting', 'NN', 'o'), ('in', 'IN', 'o'), ('the', 'DT', 'o'), ('of', 'IN', 'o'), ('the', 'DT', 'o'), ('does', 'VBZ', 'o'), ('not', 'RB', 'o'), ('seem', 'VB', 'o'), ('to', 'TO', 'o'), ('do', 'VB', 'o'), ('anything.Did', 'VB', 'o'), ('I', 'PRP', 'o'), ('overlook', 'VBP', 'o'), ('something', 'NN', 'o'), ('?', '.', 'o'), ('Is', 'VBZ', 'o'), ('there', 'EX', 'o'), ('a', 'DT', 'o'), ('way', 'NN', 'o'), ('to', 'TO', 'o'), ('have', 'VB', 'o'), ('separate', 'JJ', 'o'), ('php', 'NNS', 'Web development'), ('for', 'IN', 'o'), ('each', 'DT', 'o'), ('Virtual', 'NNP', 'o'), ('Host', 'NNP', 'SoftwareOperation'), ('?', '.', 'o')]\n"
     ]
    }
   ],
   "source": [
    "sent = getter.get_next()\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = getter.sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag2idx[\"o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALK4KOR\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"o\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 20)           200900    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 100)          28400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 150, 50)           5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 150, 22)           1650      \n",
      "=================================================================\n",
      "Total params: 236,000\n",
      "Trainable params: 236,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 810 samples, validate on 90 samples\n",
      "Epoch 1/50\n",
      "810/810 [==============================] - 11s 13ms/step - loss: 9.6161 - acc: 0.8625 - val_loss: 7.2709 - val_acc: 0.9716\n",
      "Epoch 2/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.9195 - acc: 0.9786 - val_loss: 7.1948 - val_acc: 0.9716\n",
      "Epoch 3/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.8675 - acc: 0.9786 - val_loss: 7.1611 - val_acc: 0.9716\n",
      "Epoch 4/50\n",
      "810/810 [==============================] - 10s 12ms/step - loss: 8.8389 - acc: 0.9788 - val_loss: 7.1376 - val_acc: 0.9716\n",
      "Epoch 5/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.8147 - acc: 0.9786 - val_loss: 7.1133 - val_acc: 0.9716\n",
      "Epoch 6/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.7883 - acc: 0.9785 - val_loss: 7.0853 - val_acc: 0.9716\n",
      "Epoch 7/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.7599 - acc: 0.9785 - val_loss: 7.0561 - val_acc: 0.9716\n",
      "Epoch 8/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.7357 - acc: 0.9802 - val_loss: 7.0393 - val_acc: 0.9741\n",
      "Epoch 9/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.7226 - acc: 0.9823 - val_loss: 7.0269 - val_acc: 0.9748\n",
      "Epoch 10/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.7149 - acc: 0.9829 - val_loss: 7.0206 - val_acc: 0.9755\n",
      "Epoch 11/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.7100 - acc: 0.9842 - val_loss: 7.0158 - val_acc: 0.9781\n",
      "Epoch 12/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.7055 - acc: 0.9851 - val_loss: 7.0127 - val_acc: 0.9779\n",
      "Epoch 13/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.7017 - acc: 0.9853 - val_loss: 7.0111 - val_acc: 0.9790\n",
      "Epoch 14/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6986 - acc: 0.9858 - val_loss: 7.0098 - val_acc: 0.9780\n",
      "Epoch 15/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6955 - acc: 0.9864 - val_loss: 7.0170 - val_acc: 0.9830\n",
      "Epoch 16/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6929 - acc: 0.9882 - val_loss: 7.0125 - val_acc: 0.9795\n",
      "Epoch 17/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6906 - acc: 0.9887 - val_loss: 7.0539 - val_acc: 0.9644\n",
      "Epoch 18/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6883 - acc: 0.9901 - val_loss: 7.0191 - val_acc: 0.9820\n",
      "Epoch 19/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6863 - acc: 0.9916 - val_loss: 7.0215 - val_acc: 0.9814\n",
      "Epoch 20/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6843 - acc: 0.9919 - val_loss: 7.0332 - val_acc: 0.9763\n",
      "Epoch 21/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6821 - acc: 0.9926 - val_loss: 7.0226 - val_acc: 0.9780\n",
      "Epoch 22/50\n",
      "810/810 [==============================] - 9s 12ms/step - loss: 8.6803 - acc: 0.9937 - val_loss: 7.0379 - val_acc: 0.9779\n",
      "Epoch 23/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6782 - acc: 0.9940 - val_loss: 7.0675 - val_acc: 0.9596\n",
      "Epoch 24/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6765 - acc: 0.9944 - val_loss: 7.1410 - val_acc: 0.9367\n",
      "Epoch 25/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6744 - acc: 0.9950 - val_loss: 7.0744 - val_acc: 0.9592\n",
      "Epoch 26/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6732 - acc: 0.9953 - val_loss: 7.1290 - val_acc: 0.9446\n",
      "Epoch 27/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6719 - acc: 0.9957 - val_loss: 7.1191 - val_acc: 0.9479\n",
      "Epoch 28/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6699 - acc: 0.9963 - val_loss: 7.1066 - val_acc: 0.9536\n",
      "Epoch 29/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6687 - acc: 0.9965 - val_loss: 7.1205 - val_acc: 0.9492\n",
      "Epoch 30/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6669 - acc: 0.9971 - val_loss: 7.4240 - val_acc: 0.9104\n",
      "Epoch 31/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6659 - acc: 0.9970 - val_loss: 7.1382 - val_acc: 0.9450\n",
      "Epoch 32/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6643 - acc: 0.9974 - val_loss: 7.1016 - val_acc: 0.9566\n",
      "Epoch 33/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6632 - acc: 0.9975 - val_loss: 7.2348 - val_acc: 0.9306\n",
      "Epoch 34/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6623 - acc: 0.9976 - val_loss: 7.1645 - val_acc: 0.9422\n",
      "Epoch 35/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6612 - acc: 0.9979 - val_loss: 7.1771 - val_acc: 0.9404\n",
      "Epoch 36/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6604 - acc: 0.9979 - val_loss: 7.3481 - val_acc: 0.9198\n",
      "Epoch 37/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6598 - acc: 0.9982 - val_loss: 7.1502 - val_acc: 0.9461\n",
      "Epoch 38/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6586 - acc: 0.9983 - val_loss: 7.2041 - val_acc: 0.9373\n",
      "Epoch 39/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6583 - acc: 0.9986 - val_loss: 7.2328 - val_acc: 0.9335\n",
      "Epoch 40/50\n",
      "810/810 [==============================] - 9s 11ms/step - loss: 8.6575 - acc: 0.9987 - val_loss: 7.2359 - val_acc: 0.9340\n",
      "Epoch 41/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6570 - acc: 0.9989 - val_loss: 7.3085 - val_acc: 0.9246\n",
      "Epoch 42/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6569 - acc: 0.9987 - val_loss: 7.3650 - val_acc: 0.9222\n",
      "Epoch 43/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6562 - acc: 0.9992 - val_loss: 7.2665 - val_acc: 0.9308\n",
      "Epoch 44/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6560 - acc: 0.9990 - val_loss: 7.3035 - val_acc: 0.9273\n",
      "Epoch 45/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6556 - acc: 0.9992 - val_loss: 7.2814 - val_acc: 0.9308\n",
      "Epoch 46/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6551 - acc: 0.9995 - val_loss: 7.3915 - val_acc: 0.9214\n",
      "Epoch 47/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6550 - acc: 0.9993 - val_loss: 7.4146 - val_acc: 0.9221\n",
      "Epoch 48/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6548 - acc: 0.9994 - val_loss: 7.4156 - val_acc: 0.9214\n",
      "Epoch 49/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6546 - acc: 0.9996 - val_loss: 7.5508 - val_acc: 0.9157\n",
      "Epoch 50/50\n",
      "810/810 [==============================] - 8s 10ms/step - loss: 8.6543 - acc: 0.9996 - val_loss: 7.4189 - val_acc: 0.9213\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=50,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
