{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48 samples, validate on 6 samples\n",
      "Epoch 1/150\n",
      "48/48 [==============================] - 3s 55ms/step - loss: 7.4105 - acc: 0.0011 - val_loss: 7.1299 - val_acc: 0.0000e+00\n",
      "Epoch 2/150\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 7.3218 - acc: 0.0340 - val_loss: 7.0071 - val_acc: 0.2549\n",
      "Epoch 3/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 7.1331 - acc: 0.2943 - val_loss: 6.7136 - val_acc: 0.4575\n",
      "Epoch 4/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.7545 - acc: 0.5254 - val_loss: 6.9553 - val_acc: 0.4641\n",
      "Epoch 5/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.6395 - acc: 0.5234 - val_loss: 6.7120 - val_acc: 0.4641\n",
      "Epoch 6/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5969 - acc: 0.5246 - val_loss: 6.7089 - val_acc: 0.4641\n",
      "Epoch 7/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.5298 - acc: 0.5254 - val_loss: 6.6999 - val_acc: 0.4641\n",
      "Epoch 8/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.5039 - acc: 0.5250 - val_loss: 6.6120 - val_acc: 0.4575\n",
      "Epoch 9/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4814 - acc: 0.5271 - val_loss: 6.7850 - val_acc: 0.4641\n",
      "Epoch 10/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.4849 - acc: 0.5256 - val_loss: 6.6450 - val_acc: 0.4641\n",
      "Epoch 11/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.4451 - acc: 0.5264 - val_loss: 6.5631 - val_acc: 0.4641\n",
      "Epoch 12/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4273 - acc: 0.5253 - val_loss: 6.5863 - val_acc: 0.4641\n",
      "Epoch 13/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4164 - acc: 0.5242 - val_loss: 6.5567 - val_acc: 0.4641\n",
      "Epoch 14/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.4034 - acc: 0.5258 - val_loss: 6.5747 - val_acc: 0.4641\n",
      "Epoch 15/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.3874 - acc: 0.5220 - val_loss: 6.4787 - val_acc: 0.4575\n",
      "Epoch 16/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.3767 - acc: 0.5250 - val_loss: 6.5440 - val_acc: 0.4641\n",
      "Epoch 17/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.3668 - acc: 0.5239 - val_loss: 6.4710 - val_acc: 0.4641\n",
      "Epoch 18/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.3627 - acc: 0.5256 - val_loss: 6.5179 - val_acc: 0.4641\n",
      "Epoch 19/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3525 - acc: 0.5263 - val_loss: 6.4592 - val_acc: 0.4641\n",
      "Epoch 20/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.3413 - acc: 0.5241 - val_loss: 6.4431 - val_acc: 0.4706\n",
      "Epoch 21/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.3312 - acc: 0.5254 - val_loss: 6.4753 - val_acc: 0.4641\n",
      "Epoch 22/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.3285 - acc: 0.5251 - val_loss: 6.4284 - val_acc: 0.4641\n",
      "Epoch 23/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.3102 - acc: 0.5261 - val_loss: 6.4003 - val_acc: 0.4641\n",
      "Epoch 24/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2978 - acc: 0.5250 - val_loss: 6.4206 - val_acc: 0.4641\n",
      "Epoch 25/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2818 - acc: 0.5255 - val_loss: 6.3948 - val_acc: 0.4706\n",
      "Epoch 26/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.2694 - acc: 0.5244 - val_loss: 6.3844 - val_acc: 0.4641\n",
      "Epoch 27/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.2608 - acc: 0.5252 - val_loss: 6.3847 - val_acc: 0.4641\n",
      "Epoch 28/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2440 - acc: 0.5266 - val_loss: 6.3531 - val_acc: 0.4641\n",
      "Epoch 29/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.2290 - acc: 0.5251 - val_loss: 6.3343 - val_acc: 0.4641\n",
      "Epoch 30/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.2018 - acc: 0.5247 - val_loss: 6.3420 - val_acc: 0.4641\n",
      "Epoch 31/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 6.1908 - acc: 0.5253 - val_loss: 6.3051 - val_acc: 0.4641\n",
      "Epoch 32/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1699 - acc: 0.5251 - val_loss: 6.2938 - val_acc: 0.4706\n",
      "Epoch 33/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1439 - acc: 0.5271 - val_loss: 6.3077 - val_acc: 0.4706\n",
      "Epoch 34/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.1140 - acc: 0.5303 - val_loss: 6.2544 - val_acc: 0.4641\n",
      "Epoch 35/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.0874 - acc: 0.5312 - val_loss: 6.2459 - val_acc: 0.4706\n",
      "Epoch 36/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 6.0593 - acc: 0.5366 - val_loss: 6.1770 - val_acc: 0.4706\n",
      "Epoch 37/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 6.0292 - acc: 0.5431 - val_loss: 6.1213 - val_acc: 0.4902\n",
      "Epoch 38/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.9881 - acc: 0.5568 - val_loss: 6.1252 - val_acc: 0.4771\n",
      "Epoch 39/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.9576 - acc: 0.5539 - val_loss: 6.0371 - val_acc: 0.5033\n",
      "Epoch 40/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.9112 - acc: 0.5800 - val_loss: 6.0350 - val_acc: 0.5033\n",
      "Epoch 41/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.8739 - acc: 0.5923 - val_loss: 5.9868 - val_acc: 0.5490\n",
      "Epoch 42/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.8388 - acc: 0.5981 - val_loss: 6.0189 - val_acc: 0.4837\n",
      "Epoch 43/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.7977 - acc: 0.6138 - val_loss: 5.9225 - val_acc: 0.5359\n",
      "Epoch 44/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7590 - acc: 0.6437 - val_loss: 5.8857 - val_acc: 0.5163\n",
      "Epoch 45/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.7234 - acc: 0.6406 - val_loss: 5.8277 - val_acc: 0.5817\n",
      "Epoch 46/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6859 - acc: 0.6667 - val_loss: 5.8147 - val_acc: 0.5621\n",
      "Epoch 47/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.6491 - acc: 0.6752 - val_loss: 5.7700 - val_acc: 0.5948\n",
      "Epoch 48/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.6260 - acc: 0.6886 - val_loss: 5.7619 - val_acc: 0.5882\n",
      "Epoch 49/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.5870 - acc: 0.6955 - val_loss: 5.6925 - val_acc: 0.6340\n",
      "Epoch 50/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5535 - acc: 0.7198 - val_loss: 5.6770 - val_acc: 0.6340\n",
      "Epoch 51/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.5144 - acc: 0.7489 - val_loss: 5.6903 - val_acc: 0.5948\n",
      "Epoch 52/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.4927 - acc: 0.7372 - val_loss: 5.6122 - val_acc: 0.6928\n",
      "Epoch 53/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.4620 - acc: 0.7617 - val_loss: 5.6044 - val_acc: 0.6601\n",
      "Epoch 54/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.4420 - acc: 0.7720 - val_loss: 5.6424 - val_acc: 0.6667\n",
      "Epoch 55/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.4125 - acc: 0.7714 - val_loss: 5.5418 - val_acc: 0.7190\n",
      "Epoch 56/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.3828 - acc: 0.7972 - val_loss: 5.5631 - val_acc: 0.6863\n",
      "Epoch 57/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.3604 - acc: 0.7929 - val_loss: 5.5257 - val_acc: 0.7320\n",
      "Epoch 58/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.3327 - acc: 0.8062 - val_loss: 5.4819 - val_acc: 0.7190\n",
      "Epoch 59/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.3055 - acc: 0.7934 - val_loss: 5.4577 - val_acc: 0.7386\n",
      "Epoch 60/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2862 - acc: 0.8263 - val_loss: 5.4404 - val_acc: 0.7647\n",
      "Epoch 61/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2623 - acc: 0.8364 - val_loss: 5.4034 - val_acc: 0.7778\n",
      "Epoch 62/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2418 - acc: 0.8452 - val_loss: 5.4012 - val_acc: 0.7647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2309 - acc: 0.8456 - val_loss: 5.4167 - val_acc: 0.7647\n",
      "Epoch 64/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.2076 - acc: 0.8304 - val_loss: 5.3535 - val_acc: 0.7712\n",
      "Epoch 65/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.1758 - acc: 0.8630 - val_loss: 5.3168 - val_acc: 0.8170\n",
      "Epoch 66/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.1666 - acc: 0.8740 - val_loss: 5.3897 - val_acc: 0.7647\n",
      "Epoch 67/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.1507 - acc: 0.8614 - val_loss: 5.3305 - val_acc: 0.7843\n",
      "Epoch 68/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.1289 - acc: 0.8818 - val_loss: 5.3190 - val_acc: 0.7843\n",
      "Epoch 69/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.1160 - acc: 0.8791 - val_loss: 5.2794 - val_acc: 0.7908\n",
      "Epoch 70/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.0864 - acc: 0.8973 - val_loss: 5.2728 - val_acc: 0.8039\n",
      "Epoch 71/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.0787 - acc: 0.8868 - val_loss: 5.2885 - val_acc: 0.7908\n",
      "Epoch 72/150\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 5.0657 - acc: 0.8849 - val_loss: 5.2752 - val_acc: 0.7908\n",
      "Epoch 73/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.0456 - acc: 0.9013 - val_loss: 5.2530 - val_acc: 0.7974\n",
      "Epoch 74/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.0401 - acc: 0.9021 - val_loss: 5.2787 - val_acc: 0.7778\n",
      "Epoch 75/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 5.0197 - acc: 0.9123 - val_loss: 5.4087 - val_acc: 0.7712\n",
      "Epoch 76/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 5.0201 - acc: 0.8998 - val_loss: 5.2423 - val_acc: 0.8105\n",
      "Epoch 77/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 5.0004 - acc: 0.9055 - val_loss: 5.2173 - val_acc: 0.8301\n",
      "Epoch 78/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9870 - acc: 0.9231 - val_loss: 5.2425 - val_acc: 0.8170\n",
      "Epoch 79/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.9784 - acc: 0.9167 - val_loss: 5.1989 - val_acc: 0.8431\n",
      "Epoch 80/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9762 - acc: 0.9130 - val_loss: 5.2001 - val_acc: 0.8431\n",
      "Epoch 81/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9551 - acc: 0.9287 - val_loss: 5.2818 - val_acc: 0.8039\n",
      "Epoch 82/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9506 - acc: 0.9155 - val_loss: 5.2456 - val_acc: 0.8039\n",
      "Epoch 83/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9417 - acc: 0.9192 - val_loss: 5.2771 - val_acc: 0.8039\n",
      "Epoch 84/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9347 - acc: 0.9287 - val_loss: 5.2908 - val_acc: 0.8235\n",
      "Epoch 85/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9195 - acc: 0.9332 - val_loss: 5.2567 - val_acc: 0.8170\n",
      "Epoch 86/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.9104 - acc: 0.9379 - val_loss: 5.2524 - val_acc: 0.7908\n",
      "Epoch 87/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.9030 - acc: 0.9456 - val_loss: 5.2348 - val_acc: 0.8366\n",
      "Epoch 88/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8915 - acc: 0.9457 - val_loss: 5.2603 - val_acc: 0.8366\n",
      "Epoch 89/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8915 - acc: 0.9433 - val_loss: 5.3126 - val_acc: 0.7974\n",
      "Epoch 90/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8868 - acc: 0.9404 - val_loss: 5.2371 - val_acc: 0.8497\n",
      "Epoch 91/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8791 - acc: 0.9441 - val_loss: 5.2663 - val_acc: 0.8235\n",
      "Epoch 92/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8711 - acc: 0.9530 - val_loss: 5.2594 - val_acc: 0.8366\n",
      "Epoch 93/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8582 - acc: 0.9482 - val_loss: 5.3015 - val_acc: 0.8301\n",
      "Epoch 94/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8564 - acc: 0.9507 - val_loss: 5.2935 - val_acc: 0.8170\n",
      "Epoch 95/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8547 - acc: 0.9532 - val_loss: 5.2805 - val_acc: 0.8431\n",
      "Epoch 96/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8371 - acc: 0.9486 - val_loss: 5.3167 - val_acc: 0.8366\n",
      "Epoch 97/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.8319 - acc: 0.9530 - val_loss: 5.3562 - val_acc: 0.8105\n",
      "Epoch 98/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8291 - acc: 0.9563 - val_loss: 5.3169 - val_acc: 0.8366\n",
      "Epoch 99/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8323 - acc: 0.9543 - val_loss: 5.2493 - val_acc: 0.8627\n",
      "Epoch 100/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.8267 - acc: 0.9590 - val_loss: 5.3111 - val_acc: 0.8431\n",
      "Epoch 101/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.8130 - acc: 0.9614 - val_loss: 5.3546 - val_acc: 0.8235\n",
      "Epoch 102/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.8057 - acc: 0.9605 - val_loss: 5.3333 - val_acc: 0.8431\n",
      "Epoch 103/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.8002 - acc: 0.9672 - val_loss: 5.3261 - val_acc: 0.8497\n",
      "Epoch 104/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7951 - acc: 0.9728 - val_loss: 5.3018 - val_acc: 0.8562\n",
      "Epoch 105/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7957 - acc: 0.9666 - val_loss: 5.4407 - val_acc: 0.8301\n",
      "Epoch 106/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7950 - acc: 0.9651 - val_loss: 5.2962 - val_acc: 0.8497\n",
      "Epoch 107/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7802 - acc: 0.9687 - val_loss: 5.3583 - val_acc: 0.8366\n",
      "Epoch 108/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7835 - acc: 0.9708 - val_loss: 5.3173 - val_acc: 0.8431\n",
      "Epoch 109/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7699 - acc: 0.9757 - val_loss: 5.4612 - val_acc: 0.8301\n",
      "Epoch 110/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7771 - acc: 0.9708 - val_loss: 5.3416 - val_acc: 0.8431\n",
      "Epoch 111/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7680 - acc: 0.9779 - val_loss: 5.4027 - val_acc: 0.8562\n",
      "Epoch 112/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7650 - acc: 0.9764 - val_loss: 5.3926 - val_acc: 0.8366\n",
      "Epoch 113/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7606 - acc: 0.9847 - val_loss: 5.3503 - val_acc: 0.8562\n",
      "Epoch 114/150\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 4.7593 - acc: 0.9776 - val_loss: 5.4276 - val_acc: 0.8431\n",
      "Epoch 115/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7573 - acc: 0.9795 - val_loss: 5.4994 - val_acc: 0.8301\n",
      "Epoch 116/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7563 - acc: 0.9816 - val_loss: 5.4210 - val_acc: 0.8431\n",
      "Epoch 117/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7464 - acc: 0.9825 - val_loss: 5.4055 - val_acc: 0.8366\n",
      "Epoch 118/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7417 - acc: 0.9855 - val_loss: 5.3437 - val_acc: 0.8954\n",
      "Epoch 119/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7476 - acc: 0.9790 - val_loss: 5.3796 - val_acc: 0.8627\n",
      "Epoch 120/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7425 - acc: 0.9844 - val_loss: 5.4965 - val_acc: 0.8366\n",
      "Epoch 121/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7352 - acc: 0.9898 - val_loss: 5.4497 - val_acc: 0.8301\n",
      "Epoch 122/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7398 - acc: 0.9854 - val_loss: 5.3695 - val_acc: 0.8758\n",
      "Epoch 123/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7285 - acc: 0.9864 - val_loss: 5.4674 - val_acc: 0.8431\n",
      "Epoch 124/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7248 - acc: 0.9907 - val_loss: 5.4920 - val_acc: 0.8366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7255 - acc: 0.9894 - val_loss: 5.6103 - val_acc: 0.8170\n",
      "Epoch 126/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7266 - acc: 0.9897 - val_loss: 5.4285 - val_acc: 0.8627\n",
      "Epoch 127/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7180 - acc: 0.9948 - val_loss: 5.5224 - val_acc: 0.8301\n",
      "Epoch 128/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7212 - acc: 0.9905 - val_loss: 5.4628 - val_acc: 0.8431\n",
      "Epoch 129/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7191 - acc: 0.9876 - val_loss: 5.4205 - val_acc: 0.8627\n",
      "Epoch 130/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7177 - acc: 0.9884 - val_loss: 5.5616 - val_acc: 0.8366\n",
      "Epoch 131/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7172 - acc: 0.9884 - val_loss: 5.6108 - val_acc: 0.8170\n",
      "Epoch 132/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7141 - acc: 0.9936 - val_loss: 5.4603 - val_acc: 0.8497\n",
      "Epoch 133/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7075 - acc: 0.9969 - val_loss: 5.5130 - val_acc: 0.8431\n",
      "Epoch 134/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7061 - acc: 0.9958 - val_loss: 5.5051 - val_acc: 0.8497\n",
      "Epoch 135/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7062 - acc: 0.9937 - val_loss: 5.7135 - val_acc: 0.8366\n",
      "Epoch 136/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7091 - acc: 0.9905 - val_loss: 5.4908 - val_acc: 0.8301\n",
      "Epoch 137/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7095 - acc: 0.9903 - val_loss: 5.5232 - val_acc: 0.8366\n",
      "Epoch 138/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.7035 - acc: 0.9948 - val_loss: 5.5533 - val_acc: 0.8366\n",
      "Epoch 139/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.7029 - acc: 0.9932 - val_loss: 5.4963 - val_acc: 0.8562\n",
      "Epoch 140/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.6999 - acc: 0.9926 - val_loss: 5.5229 - val_acc: 0.8301\n",
      "Epoch 141/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.6961 - acc: 0.9969 - val_loss: 5.5019 - val_acc: 0.8758\n",
      "Epoch 142/150\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 4.7007 - acc: 0.9936 - val_loss: 5.5603 - val_acc: 0.8366\n",
      "Epoch 143/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.6938 - acc: 0.9978 - val_loss: 5.5819 - val_acc: 0.8366\n",
      "Epoch 144/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6971 - acc: 0.9959 - val_loss: 5.5719 - val_acc: 0.8431\n",
      "Epoch 145/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6952 - acc: 0.9959 - val_loss: 5.6271 - val_acc: 0.8301\n",
      "Epoch 146/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.6950 - acc: 0.9991 - val_loss: 5.6212 - val_acc: 0.8366\n",
      "Epoch 147/150\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 4.6965 - acc: 0.9928 - val_loss: 5.6422 - val_acc: 0.8235\n",
      "Epoch 148/150\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 4.6960 - acc: 0.9957 - val_loss: 5.6386 - val_acc: 0.8301\n",
      "Epoch 149/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6898 - acc: 0.9991 - val_loss: 5.5954 - val_acc: 0.8301\n",
      "Epoch 150/150\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 4.6885 - acc: 0.9989 - val_loss: 5.5943 - val_acc: 0.8824\n"
     ]
    }
   ],
   "source": [
    "#model with CRF Max_len = 75\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras_contrib.layers import CRF\n",
    "import numpy\n",
    "numpy.random.seed(7)\n",
    "data = pd.read_csv('/home/sharath/Documents/torchdata/lmscsv/bcmtokens.csv', encoding='latin1', sep = ',')\n",
    "data = data.fillna(method=\"ffill\")\n",
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words\n",
    "tags = list(set(data[\"Tag\"].values))\n",
    "n_tags = len(tags); n_tags\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "getter = SentenceGetter(data)\n",
    "sent = getter.get_next()\n",
    "sentences = getter.sentences\n",
    "max_len = 50\n",
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Save\n",
    "np.save('/home/sharath/Documents/savedweights_Bilstm/word2idxcrfbcm.npy', word2idx) \n",
    "\n",
    "# Load\n",
    "#word2idx = np.load('C:\\\\Users\\\\sharath\\\\Desktop\\\\exp\\\\word2idx.npy').item()\n",
    "\n",
    "\n",
    "# Save\n",
    "np.save('/home/sharath/Documents/savedweights_Bilstm/tag2idxcrfbcm.npy', tag2idx) \n",
    "\n",
    "# Load\n",
    "#tag2idx = np.load('C:\\\\Users\\\\sharath\\\\Desktop\\\\exp\\\\tag2idx.npy').item()\n",
    "\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=0)\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output\n",
    "\n",
    "model = Model(input, out)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "history = model.fit(X_tr, np.array(y_tr), batch_size=20, epochs=150,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"The architecture of Hatch washer consists of a gateway connection to Controller Area Network signal BUS and a combination BUS.\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newpredict(tt):\n",
    "    result = []\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in tt]],\n",
    "                            padding=\"post\", value=0, maxlen=max_len)\n",
    "    p = model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, pred in zip(tt, p[0]):\n",
    "        result.append((w, tags[pred]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('architecture', 'O'),\n",
       " ('of', 'O'),\n",
       " ('Hatch', 'auxillary system'),\n",
       " ('washer', 'auxillary system'),\n",
       " ('consists', 'O'),\n",
       " ('of', 'O'),\n",
       " ('a', 'O'),\n",
       " ('gateway', 'system component'),\n",
       " ('connection', 'system component'),\n",
       " ('to', 'O'),\n",
       " ('Controller', 'system component'),\n",
       " ('Area', 'system component'),\n",
       " ('Network', 'system component'),\n",
       " ('signal', 'system_signal'),\n",
       " ('BUS', 'system_signal'),\n",
       " ('and', 'O'),\n",
       " ('a', 'O'),\n",
       " ('combination', 'O'),\n",
       " ('BUS.', 'system component')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpredict(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'O'),\n",
       " ('system', 'Network_Component'),\n",
       " ('should', 'O'),\n",
       " ('do', 'O'),\n",
       " ('the', 'O'),\n",
       " ('validation', 'Action'),\n",
       " ('for', 'O'),\n",
       " ('confirm', 'Action'),\n",
       " ('password', 'Attribute'),\n",
       " ('text', 'O'),\n",
       " ('on', 'O'),\n",
       " ('submit', 'O'),\n",
       " ('of', 'O'),\n",
       " ('the', 'O'),\n",
       " ('form', 'O')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('The', 'O'),\n",
    " ('system', 'Network_Component'),\n",
    " ('should', 'O'),\n",
    " ('do', 'O'),\n",
    " ('the', 'O'),\n",
    " ('validation', 'Action'),\n",
    " ('for', 'O'),\n",
    " ('confirm', 'Action'),\n",
    " ('password', 'Attribute'),\n",
    " ('text', 'O'),\n",
    " ('on', 'O'),\n",
    " ('submit', 'O'),\n",
    " ('of', 'O'),\n",
    " ('the', 'O'),\n",
    " ('form', 'O')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 0s 2ms/step\n",
      "acc: 98.36%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_tr, np.array(y_tr), verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_objects={'CRF':CRF}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras_contrib.layers import CRF\n",
    "# load json and create model\n",
    "json_file = open('/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json, custom_objects={'CRF':CRF})\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sharath'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = loaded_model.evaluate(X_tr, np.array(y_tr), verbose=1)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilstmfinalcrf(test_sentence):\n",
    "    from keras.models import load_model\n",
    "    from keras_contrib.layers import CRF, crf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from keras.models import model_from_json\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    from keras.models import Model, Input\n",
    "    from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.utils import to_categorical\n",
    "    import numpy\n",
    "    numpy.random.seed(7)\n",
    "    word2idx = np.load('/home/sharath/Documents/savedweights_Bilstm/word2idxcrfbcm.npy').item()\n",
    "    tag2idx = np.load('/home/sharath/Documents/savedweights_Bilstm/tag2idxcrfbcm.npy').item()\n",
    "    # load json and create model\n",
    "    json_file = open('/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json,custom_objects={'CRF':CRF})\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.h5\")\n",
    "    loaded_model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])\n",
    "    test_sentence = test_sentence.split(\" \")\n",
    "    x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
    "                            padding=\"post\", value=0, maxlen=50)\n",
    "    p = loaded_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    pls = []\n",
    "    p = loaded_model.predict(np.array([x_test_sent[0]]))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    for w, pred in zip(test_sentence, p[0]):\n",
    "        pls.append(pred)\n",
    "    revsubs = { v:k for k,v in tag2idx.items()}\n",
    "    entit = [revsubs.get(item,item) for item in pls]\n",
    "    final = list(zip(test_sentence,entit))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"The architecture of Hatch washer consists of a gateway connection to Controller Area Network signal BUS and a combination BUS.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras_contrib.layers.crf' has no attribute 'loss_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0d802e62c1b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbilstmfinalcrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-87ec3e6246aa>\u001b[0m in \u001b[0;36mbilstmfinalcrf\u001b[0;34m(test_sentence)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# load weights into new model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/sharath/Documents/savedweights_Bilstm/modelcrfbcm.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mtest_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     x_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in test_sentence]],\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras_contrib.layers.crf' has no attribute 'loss_function'"
     ]
    }
   ],
   "source": [
    "bilstmfinalcrf(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[('Half', 'Main_Application'),\n",
    " ('day', 'O'),\n",
    " ('leave', 'O'),\n",
    " ('of', 'O'),\n",
    " ('CL', 'Leave_category'),\n",
    " ('(', 'O'),\n",
    " ('Casual', 'Leave_category'),\n",
    " ('Leave', 'App_feature'),\n",
    " (')', 'O'),\n",
    " ('is', 'O'),\n",
    " ('allowed', 'O'),\n",
    " ('for', 'O'),\n",
    " ('Mechanic', 'Title'),\n",
    " ('employees.', 'App_feature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def lstm_model():\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "#     from keras.models import load_model\n",
    "\n",
    "\n",
    "#     data = pd.read_csv('C:\\\\users\\\\sharath\\\\postags_v1.csv', encoding='latin1', sep = ',')\n",
    "#     data = data.fillna(method=\"ffill\")\n",
    "#     words = list(set(data[\"Word\"].values))\n",
    "#     words.append(\"ENDPAD\")\n",
    "#     n_words = len(words)\n",
    "#     tags = list(set(data[\"Tag\"].values))\n",
    "#     n_tags = len(tags)\n",
    "\n",
    "#     class SentenceGetter(object):\n",
    "\n",
    "#         def __init__(self, data):\n",
    "#             self.n_sent = 1\n",
    "#             self.data = data\n",
    "#             self.empty = False\n",
    "#             agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "#                                                                s[\"POS\"].values.tolist(),\n",
    "#                                                                s[\"Tag\"].values.tolist())]\n",
    "#             self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "#             self.sentences = [s for s in self.grouped]\n",
    "\n",
    "#         def get_next(self):\n",
    "#             try:\n",
    "#                 s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "#                 self.n_sent += 1\n",
    "#                 return s\n",
    "#             except:\n",
    "#                 return None\n",
    "\n",
    "#     getter = SentenceGetter(data)\n",
    "#     sent = getter.get_next()\n",
    "#     sentences = getter.sentences\n",
    "#     max_len = 50\n",
    "#     word2idx = {w: i for i, w in enumerate(words)}\n",
    "#     tag2idx = {t: i for i, t in enumerate(tags)}\n",
    "#     from keras.preprocessing.sequence import pad_sequences\n",
    "#     X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "#     X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words - 1)\n",
    "#     y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "#     y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])\n",
    "#     from keras.utils import to_categorical\n",
    "#     y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "#     from sklearn.model_selection import train_test_split\n",
    "#     X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)\n",
    "#     from keras.models import Model, Input\n",
    "#     from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "#     input = Input(shape=(max_len,))\n",
    "#     model = Embedding(input_dim=n_words, output_dim=50, input_length=max_len)(input)\n",
    "#     model = Dropout(0.1)(model)\n",
    "#     model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "#     out = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(model)  # softmax output layer\n",
    "#     model = Model(input, out)\n",
    "#     model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "#     history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=10, validation_split=0.1, verbose=1)\n",
    "#     history.model.save('m3odel.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#     del model  # deletes the existing model\n",
    "#     # returns a compiled model\n",
    "#     # identical to the previous one\n",
    "#     modelkk = load_model('m3odel.h5')\n",
    "#     return modelkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'MatMul_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n\nCaused by op 'MatMul_1', defined at:\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-6b0c34a43aa7>\", line 5, in <module>\n    c = tf.matmul(a, b)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2022, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2799, in _mat_mul\n    name=name)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1320\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           tf_session.TF_ExtendGraph(\n\u001b[1;32m-> 1381\u001b[1;33m               self._session, graph_def.SerializeToString(), status)\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MatMul_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6b0c34a43aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'MatMul_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n\nCaused by op 'MatMul_1', defined at:\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-6b0c34a43aa7>\", line 5, in <module>\n    c = tf.matmul(a, b)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2022, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 2799, in _mat_mul\n    name=name)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\sharath\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'MatMul_1': Operation was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/device:GPU:0\"](a, b)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x1ba7dc0d0f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = \"The system shall allow the data manager to search occurrence resources by keywords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tt = \"The system shall allow the data manager to edit the metadata of an institution resource\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
